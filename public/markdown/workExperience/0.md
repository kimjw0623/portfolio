  __MLOps 시스템 구축__ __(_Jan. 2023 ~ present_)__

  - __Performance__
    - 기존에 사내에서 학습하고 배포하던 문서 이해 모델을 확장하여 MLOps 시스템을 구축하고 기업의 On-premise 환경에 도입하는 프로젝트 참여
    - 모델 학습 컨테이너를 배포하여 학습 관련 요청 처리 및 변환 API 구현, 실시간 학습 모니터링 기능 지원
    - 모델 구조와 가중치 유출 방지를 위해 학습, 배포 등 전 과정에서 모델이 암호화된 상태로 저장되도록 구현
    - 사내에서도 해당 시스템을 구축하여 모델 학습 과정과 모델 추적 및 재현 간소화

  - __Tech stacks__: Triton Inference Server, Docker, Pytorch, Celery, Redis, FastAPI, PostgreSQL
  ---

  __모델 서빙 파이프라인 개선__ __(_Nov. 2023 ~ present_)__

  - __Performance__
    - 문서 종류에 따라 다른 모델 workflow를 구현하기 위한 모델 추론 파이프라인 구축 및 유지 보수, 편의성 개선, 성능 개선 작업을 진행
    - 문서 유형별로 상이한 모델 workflow 와 비즈니스 로직을 설정 파일에서 정의하여 코드의 일관성을 유지하고, 유지보수 및 개발 효율성 증대
    - Triton Inference Server 의 Dynamic batching 기능을 사용하여, 여러 추론 요청을 효과적으로 병합하여 추론 성능 약 5% 개선
    - Triton Inference Server 의 CUDA Shared Memory 기능을 사용하여, 모델 입출력 데이터 전송 시간을 줄여 추론 성능 약 30% 개선

  - __Tech stacks__: Triton Inference Server, Docker, Celery, FastAPI
  ---

  __문서 정보 추출__ __(_July. 2023. ~ present_)__

  - __Performance__
    - 정부문서 , 금융 문서 등 다양한 문서들로부터 테이블, Key-Value 정보를 추출하는 프로젝트 다수 진행
    - 다양한 종류의 문서를 효과적으로 처리하기 위해 여러 모델들에 대해 Pretraining 및 Fine-tuning 을 수행하여, 각각의 문서에 최적화된 모델 학습
  
  - __Tech stacks__: Triton Inference Server, Pytorch

  ---

  __신분증 인식 프로젝트__ __(_Apr. 2023 ~ Jul. 2023_)__

  - __Performance__
    - OCR-Free document understanding 모델 (Auto-regressive Language Model) 을 도입하여 OCR 모델 없이도 신분증의 정보를 추출할 수 있도록 개선
    - Multi-modal encoder-decoder 모델 도입 후 새로운 pre-training task를 정의 후 학습하여 다양한 환경에서도 잘 작동하고, 신분증 정보의 위치까지 추론 가능하도록 개선
    - KV caching 등을 통해 추론 속도 개선
    - 여권, 주민등록증 등의 신분증 인식률을 기존 85%에서 97%로 개선하여 기업에 서비스

  - __Tech stacks__: Docker, Pytorch